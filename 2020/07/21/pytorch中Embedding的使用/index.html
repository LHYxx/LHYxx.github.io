<!DOCTYPE html>
<html lang="zh-cmn-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content>
    <link rel="shortcut icon" href="/img/book.png">
    <title>pytorch中Embedding的使用-小新xx</title>
    
        
            <link href="https://cdn.bootcss.com/twitter-bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet">
            <link href="https://cdn.bootcss.com/academicons/1.8.6/css/academicons.min.css" rel="stylesheet">
            <link href="https://cdn.bootcss.com/font-awesome/5.9.0/css/all.min.css" rel="stylesheet">
            <link href="https://cdn.bootcss.com/animate.css/3.7.2/animate.min.css" rel="stylesheet">
        
    
    <link rel="stylesheet" href="/css/adagio.css">

    <style type="text/css">
        .jumbotron{
            background: url();
            background-repeat: no-repeat;
            background-size: 100% 100%;
        }
        .tag-list{
            font-weight: bold;
            font-size: 200;
            color: red;
        }
    </style>

<!-- 下面是对mathjax的设置 -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      linebreaks: {automatic: ['\\']}
    },
    "HTML-CSS": { linebreaks: { automatic: true } },
         SVG: { linebreaks: { automatic: true } }
  });
</script>



</head>
<body>
    <div class="container-fluid">
    <nav class="nav">
        <div class="collapse navbar-collapse" id="navbar-sm">
            
            
            <div class="navbar-nav">
                <a href="/index.html" class="nav-item nav-link">主页</a>
            </div>
            
            <div class="navbar-nav">
                <a href="/others/aboutme.html" class="nav-item nav-link">LHYxx</a>
            </div>
            
        </div>
    </nav>
</div>

<div class="d-flex d-md-none" style="width: 100%; background-color: #e9ecef">
    <div class="nav">
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-sm"
            aria-expanded="false" aria-label="Toggle Navigation">
            <i class="fas fa-bars fa-lg"></i>
        </button>
    </div>
    <nav class="navbar ml-auto">
        <a class="navbar-brand" href="/">
            
            LHYxx
            
        </a>
    </nav>
</div>


<div class="container d-none d-md-block my-navbar">
    <nav class="navbar navbar-expand-sm navbar-light bg-transparent">
        <a class="navbar-brand " href="/">
            
            LHYxx
            
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
            aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNav">
            <ul class="navbar-nav">
                
                <li class="nav-item pl-2 pr-2 ">
                    <a class="nav-link" href="/index.html">主页</a>
                </li>
                
                <li class="nav-item pl-2 pr-2 ">
                    <a class="nav-link" href="/others/aboutme.html">LHYxx</a>
                </li>
                
            </ul>
        </div>
    </nav>
</div>




    <div class="jumbotron jumbotron-fluid">
<!-- <div class="jumbotron jumbotron-fluid" style="background-image: url()"> -->
    <div class="container" >
        
        <h1 class="mt-4 article-title page-title" style="font-weight: bold; color: black">pytorch中Embedding的使用</h1>
        
        <p class="lead text-gray mt-3" style="color: black">By 小新; Published on 2020-07-21</p>
        
        <div class="tags">
            <ul class="tag-list">
                
                <li class="tag-list-item">
                    <a class="tag-list-link" href="/tags/pytorch/">pytorch</a>
                </li>
                
                <li class="tag-list-item">
                    <a class="tag-list-link" href="/tags/embedding/">embedding</a>
                </li>
                
            </ul>
        </div>
        
    </div>
</div>
    <div class="container">
        <div class="row">
            <div class="col-md-9 pt-2">
                <div class="row">
                    <div class="col-12">
                        <main>
                            <article class="article-text page-content"><h1 id="pytorch中Embedding的使用"><a href="#pytorch中Embedding的使用" class="headerlink" title="pytorch中Embedding的使用"></a>pytorch中Embedding的使用</h1><p>在nlp任务中，词向量（word embedding）是一个逃不开的环节。在pytorch中有专门的Embedding模块。<br>本文学习一下在pytorch中使用Embedding的方法和一些注意事项，来避免其中的一些坑。</p>
<h2 id="pytorch-nn-Embedding"><a href="#pytorch-nn-Embedding" class="headerlink" title="pytorch.nn.Embedding"></a>pytorch.nn.Embedding</h2><h3 id="模块声明"><a href="#模块声明" class="headerlink" title="模块声明"></a>模块声明</h3><p><code>torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None)</code><br>该函数就是一个简单的look-up-table，可以理解为保存固定大小的词表的字典。<br>基本使用方法就是用来保存单词的embedding，然后我们可以用单词的索引index来检索单词对应的embedding。<br>所以输入就是包含索引的list，返回就是对应索引单词的embedding。</p>
<h3 id="模块参数说明"><a href="#模块参数说明" class="headerlink" title="模块参数说明"></a>模块参数说明</h3><ul>
<li><strong><code>num_embeddings (int)</code></strong> – 词表大小</li>
<li><strong><code>embedding_dim (int)</code></strong> – embedding的维度</li>
<li><strong><code>padding_idx (int, optional)</code></strong> – 指定padding的索引。索引padding_idx对应的embedding默认为0向量。</li>
<li><strong><code>max_norm (float, optional)</code></strong> – 如果指定max_norm，则norm超过该值的embedding会被归一化到该值。</li>
<li><strong><code>norm_type (float, optional)</code></strong> – max_norm使用的norm类型，如1-norm，2-norm等，默认为2-norm。</li>
<li><strong><code>scale_grad_by_freq (boolean, optional)</code></strong> – 如果设置为True，会用单词在mini-batch中的频率的倒数对梯度进行缩放。</li>
<li><strong><code>sparse (bool, optional)</code></strong> – 如果设置为True，对weight的梯度矩阵将为sparse tensor。目前支持sparse gradient的优化器只有：optim.SGD (CUDA and CPU), optim.SparseAdam (CUDA and CPU) and optim.Adagrad (CPU)</li>
</ul>
<h3 id="该模块包含变量"><a href="#该模块包含变量" class="headerlink" title="该模块包含变量"></a>该模块包含变量</h3><ul>
<li><strong><code>Embedding.weight (Tensor)</code></strong> – 即该模块要学习的参数，也就是词向量，初始化是从标准N(0,1)分布中初始化，shape为(num_embeddings, embedding_dim)。通过学习该参数，就可以得到词向量表示。</li>
</ul>
<h3 id="官方文档给出的例子："><a href="#官方文档给出的例子：" class="headerlink" title="官方文档给出的例子："></a>官方文档给出的例子：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># an Embedding module containing 10 tensors of size 3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>embedding = nn.Embedding(<span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># a batch of 2 samples of 4 indices each</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.LongTensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>],[<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>embedding(input)</span><br><span class="line">tensor([[[<span class="number">-0.0251</span>, <span class="number">-1.6902</span>,  <span class="number">0.7172</span>],</span><br><span class="line">         [<span class="number">-0.6431</span>,  <span class="number">0.0748</span>,  <span class="number">0.6969</span>],</span><br><span class="line">         [ <span class="number">1.4970</span>,  <span class="number">1.3448</span>, <span class="number">-0.9685</span>],</span><br><span class="line">         [<span class="number">-0.3677</span>, <span class="number">-2.7265</span>, <span class="number">-0.1685</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">1.4970</span>,  <span class="number">1.3448</span>, <span class="number">-0.9685</span>],</span><br><span class="line">         [ <span class="number">0.4362</span>, <span class="number">-0.4004</span>,  <span class="number">0.9400</span>],</span><br><span class="line">         [<span class="number">-0.6431</span>,  <span class="number">0.0748</span>,  <span class="number">0.6969</span>],</span><br><span class="line">         [ <span class="number">0.9124</span>, <span class="number">-2.3616</span>,  <span class="number">1.1151</span>]]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># example with padding_idx</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>embedding = nn.Embedding(<span class="number">10</span>, <span class="number">3</span>, padding_idx=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.LongTensor([[<span class="number">0</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">5</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>embedding(input)</span><br><span class="line">tensor([[[ <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">         [ <span class="number">0.1535</span>, <span class="number">-2.0309</span>,  <span class="number">0.9315</span>],</span><br><span class="line">         [ <span class="number">0.0000</span>,  <span class="number">0.0000</span>,  <span class="number">0.0000</span>],</span><br><span class="line">         [<span class="number">-0.1655</span>,  <span class="number">0.9897</span>,  <span class="number">0.0635</span>]]])</span><br></pre></td></tr></table></figure>

<h3 id="预训练的词向量"><a href="#预训练的词向量" class="headerlink" title="预训练的词向量"></a>预训练的词向量</h3><p>nn.Embedding模块初始化的向量是随机初始化的，没有任何含义。可以通过训练学习得到具有语义含义的词向量。<br>有时我们想加载某些预训练好的词向量，然后基于预训练的词向量进行后续的模型学习。</p>
<p>nn.Embedding模块除了可以随机初始化，还可以<strong>直接加载已有的词向量</strong>。<br><code>from_pretrained(embeddings, freeze=True, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)</code><br>该方法使用一个2维的FloatTensor创建Embedding实例。</p>
<p>参数说明</p>
<ul>
<li><strong><code>embeddings (FloatTensor)</code></strong> – 预训练的词向量矩阵，2维FloatTensor。第一维度就相当于词表大小，第二维度就相当于embedding维度。</li>
<li><strong><code>freeze (boolean, optional)</code></strong> – 训练过程中是否冻结embedding部分的参数。默认为True。如果为True则后续的模型训练，参数更新过程中，embedding的参数不会更新。</li>
<li>其他参数与上面参数含义相同</li>
</ul>
<p><strong>官方文档给出的示例</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># FloatTensor containing pretrained weights</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>weight = torch.FloatTensor([[<span class="number">1</span>, <span class="number">2.3</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5.1</span>, <span class="number">6.3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>embedding = nn.Embedding.from_pretrained(weight)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Get embeddings for index 1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.LongTensor([<span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>embedding(input)</span><br><span class="line">tensor([[ <span class="number">4.0000</span>,  <span class="number">5.1000</span>,  <span class="number">6.3000</span>]])</span><br></pre></td></tr></table></figure>

<h3 id="使用的一般流程"><a href="#使用的一般流程" class="headerlink" title="使用的一般流程"></a>使用的一般流程</h3><p>首先不管是英文预料还是中文预料，不管是以单词为单位还是以字符（字）为单位，首先都是建立词典。<br>类似<code>dict = {&#39;a&#39;:1, &#39;b&#39;:2, &#39;c&#39;:3, ...}</code>的形式。<br>然后，将每个句子转换为单词索引的形式，例如句子<code>abbc</code>按照上面的词典就是<code>[1, 2, 2, 3]</code>，然后所有句子组成一个list：<code>[[sent1], [sent2]]</code>。<br>由于句子长度通常不一样，因此需要进行padding，将所有句子变为相同的长度。<br>padding后的样例比如：<code>[[1, 2, 3, 0], [1, 2, 2, 3]]</code>，索引为0的地方就是padding补充的，在模型中则会对应0向量。<br>然后变为Tensor形式就可以输入模型了。</p>
<h3 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h3><p>最近疫情形式渐缓，学校终于允许学生返校了。<br>一咬牙一跺脚，放弃了在家的安逸生活，填写了返校申请。<br>虽然说着在家也能学习嘛，但是自己最清楚不过，在家的效率远远没有在学校效率高。<br>回学校继续努力！<br>哈哈我的校园，许久不见，我又回来啦！<br>遗憾的是，我的小树已经离我而去了。<br><img src="%E5%B0%8F%E6%A0%91.jpg" alt="小树.jpg"></p>
</article>
                        </main>
                        
                        
                    </div>
                </div>
                <div class="row mt-5 mb-5">
                    <div class="col-12">
                        <div class="row">
    <div class="col">
        <nav aria-label="paginator" class="paginator">
            <ul class="pagination d-none d-md-flex pagination-lg justify-content-center">
                <li class="page-item  disabled ">
                    <a class="page-link"
                        href=""
                        aria-label="Previous">
                        <span aria-hidden="true">&laquo;
                            No more</span>
                        <span class="sr-only">Previous</span>
                    </a>
                </li>
                <li class="page-item ">
                    <a class="page-link"
                        href="/2020/03/11/c指针与数组解析/"
                        aria-label="Next">
                        <span
                            aria-hidden="true">c指针与数组解析
                            &raquo;</span>
                        <span class="sr-only">Next</span>
                    </a>
                </li>
            </ul>
            <ul class="pagination d-md-none justify-content-center">
                <li class="page-item  disabled ">
                    <a class="page-link"
                        href=""
                        aria-label="Previous">
                        <span aria-hidden="true">&laquo;
                            No more</span>
                        <span class="sr-only">Previous</span>
                    </a>
                </li>
                <li class="page-item ">
                    <a class="page-link"
                        href="/2020/03/11/c指针与数组解析/"
                        aria-label="Next">
                        <span
                            aria-hidden="true">c指针与数组解析
                            &raquo;</span>
                        <span class="sr-only">Next</span>
                    </a>
                </li>
            </ul>
        </nav>
    </div>
</div>



                    </div>
                </div>
                <div class="row">
                    <div class="col-12">
                        <div id="vcomment"></div>
                    </div>
                </div>
            </div>
            <div class="col-md-3">
                <div class="container pt-4 page-sidebar">
                    
                    <div class="row">
    <div class="col">
        <h6>APPLAUSE FOR ME</h6>
        <div id="applause-easy"></div>
    </div>
</div>
                    
                    <hr class="row">
                    <div class="row toc-container">
                        <div class="col-12">
                            <h6>NAVIGATION</h6>
                            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#pytorch中Embedding的使用"><span class="toc-text">pytorch中Embedding的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#pytorch-nn-Embedding"><span class="toc-text">pytorch.nn.Embedding</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#模块声明"><span class="toc-text">模块声明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模块参数说明"><span class="toc-text">模块参数说明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#该模块包含变量"><span class="toc-text">该模块包含变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#官方文档给出的例子："><span class="toc-text">官方文档给出的例子：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#预训练的词向量"><span class="toc-text">预训练的词向量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用的一般流程"><span class="toc-text">使用的一般流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#题外话"><span class="toc-text">题外话</span></a></li></ol></li></ol></li></ol>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <footer>
    <div class="jumbotron jumbotron-fluid mb-0">
        <div class="container-fluid">
            <div class="col text-center">
                <div class="bottom-social">
                    <div class="row">
    <div class="col text-center">
        <ul class="list-inline">
            
            <li class="list-inline-item">
                
                <a href="https://github.com/LHYxx">
                    <span class="fa-stack fa-2x icon-link">
                        <i class="fas fa-circle fa-stack-2x"></i>
                        <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                    </span>
                </a>
                
            </li>
            
            <li class="list-inline-item">
                
                <a href="https://www.zhihu.com/people/zhihu_name">
                    <span class="fa-stack fa-2x icon-link">
                        <i class="fas fa-circle fa-stack-2x"></i>
                        <i class="fab fa-zhihu fa-stack-1x fa-inverse"></i>
                    </span>
                </a>
                
            </li>
            
        </ul>
    </div>
</div>

                </div>
                <p class="copyright text-muted">
                    Copyright &copy; 小新xx
                    <br>
                    感谢支持！
                    <br>
                    <a href="http://cs.scu.edu.cn/">海纳百川</a>, 
                    <a href="http://www.tju.edu.cn/">实事求是</a>.
                </p>
            </div>
        </div>
    </div>
</footer>

    
    
        <script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.slim.min.js"></script>
        <script src="https://cdn.bootcss.com/twitter-bootstrap/4.3.1/js/bootstrap.bundle.min.js"></script>
        <script src="https://cdn.bootcss.com/font-awesome/5.9.0/js/all.min.js"></script>
         
            <script type="text/x-mathjax-config">
                MathJax.Hub.Config({
                    CommonHTML: { linebreaks: { automatic: true } },
                    "HTML-CSS": { linebreaks: { automatic: true } },
                    SVG: { linebreaks: { automatic: true } }
                });
            </script>
            <script src='https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
        
    


<script src="/js/av.min.js"></script>
<script src="/js/valine.min.js"></script>
<script src="/js/applause-easy.js"></script>

<script>
$(document).ready(function() {
    var a = new ApplauseEasy({
        id: 'applause-easy',
        appId: "xxxxxxxxxx",
        appKey: "xxxxxxxxxx",
        img_src: "http://img.hanlindong.com/blog/site/clap.png",
        img_width: "50px",
        img_height: "50px"
    })
})
</script>


<script>
    var _hmt = _hmt || [];
    (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?e8a203f609d8ced2c71c3eee859b6941";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>




    
</body>
</html>